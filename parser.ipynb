{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Params\n",
    "\n",
    "#### Required\n",
    "\n",
    "* author = set[ author1, author2, ... ]\n",
    "* level = pick1: beginner, novice, intermediate, advanced\n",
    "* duration = 45 (implicit: minutes)\n",
    "\n",
    "#### Derived\n",
    "* libraries = (compiled from cell)\n",
    "* git-info = dict{version; source; sha1; last-modified-date}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "def gitter(path='.'):\n",
    "    \"\"\"\n",
    "    Try to collect GitHub information to use in tracking \n",
    "    authorship contributions and allow specification of\n",
    "    particular versions of notebooks.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    path: String\n",
    "        The path to a GitHub repository. Defaults to '.'\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    rp: dict\n",
    "        A dictionary containing relevant git metadata\n",
    "    \"\"\"\n",
    "    repo = Repo(path)\n",
    "    \n",
    "    rp = {}\n",
    "    \n",
    "    rp['active_branch'] = str(repo.active_branch)\n",
    "    \n",
    "    hc = repo.head.commit\n",
    "    rp['author.name'] = hc.author.name\n",
    "    rp['authored_date'] = datetime.datetime.fromtimestamp(hc.authored_date).strftime('%y-%m-%d %H:%M:%S')\n",
    "    rp['committer.name'] = hc.committer.name\n",
    "    rp['committed_date'] = datetime.datetime.fromtimestamp(hc.committed_date).strftime('%y-%m-%d %H:%M:%S')\n",
    "    rp['sha'] = hc.hexsha\n",
    "    \n",
    "    return rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author.name': u'jreades', 'committer.name': u'jreades', 'sha': u'e3386a990462c6c79c81f6ae108824e0770b7e17', 'committed_date': '17-02-22 11:03:01', 'active_branch': 'master', 'authored_date': '17-02-22 11:03:01'}\n"
     ]
    }
   ],
   "source": [
    "print(gitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_nb(nb, ext=True):\n",
    "    \"\"\"\n",
    "    Read a notebook file and return a notebook object.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: String\n",
    "        Path to the notebook file; if the path does not end\n",
    "        in '.ipynb' then this will be appended unless you\n",
    "        override this by setting the 'ext' to False.\n",
    "    ext: boolean\n",
    "        Defaults to True, meaning that the '.ipynb'\n",
    "        extension will be automatically added. If you do not\n",
    "        want this behaviour for some reason then set ext to False.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    An object of class nbformat.notebooknode.NotebookNode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append file extension if missing and ext is True\n",
    "    if not nb.endswith('.ipynb') and ext is True:\n",
    "        nb += '.ipynb'\n",
    "    \n",
    "    # Read-only in UTF-8, note NO_CONVERT.\n",
    "    with io.open(nb, 'r', encoding='utf8') as f:\n",
    "        nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "    \n",
    "    return nb\n",
    "\n",
    "def write_nb(nb, fn):\n",
    "    \"\"\"\n",
    "    Write a notebook to the path specified.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: nbformat.notebooknode.NotebookNode\n",
    "        A notebook object to write to disk.\n",
    "    fn: String\n",
    "        Path to which you want the notebook written. _Note:_ \n",
    "        for simplicity's sake this will automatically append \n",
    "        '.ipynb' to the filename; however we recommend that \n",
    "        you not get lazy and rely on this feature since it may\n",
    "        go away in the future.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append file extension\n",
    "    if not fn.endswith('.ipynb'):\n",
    "        fn += '.ipynb'\n",
    "    \n",
    "    # Write raw notebook content\n",
    "    with io.open(fn, 'w', encoding='utf8') as f:\n",
    "        nbformat.write(nb, f, nbformat.NO_CONVERT)\n",
    "\n",
    "from collections import defaultdict\n",
    "def get_nb_structure(nb):\n",
    "    cell_types = defaultdict(list)\n",
    "    for i, cell in enumerate(nb['cells']):\n",
    "        cell_types[cell.cell_type].append(i)\n",
    "    return cell_types\n",
    "\n",
    "def dump_nb(nb, cells=5, lines=5):\n",
    "    \"\"\"\n",
    "    Dump content of a notebook to STDOUT to aid in debugging.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: nbformat.notebooknode.NotebookNode\n",
    "        A notebook object from which to dump content.\n",
    "    cells: int\n",
    "        Select an arbitrary number of cells to output. Defaults to 5.\n",
    "    lines: int\n",
    "        Select an arbitrary number of lines from each cell to output. Defaults to 5.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    # For the cell-range specified\n",
    "    for c in xrange(0, cells):\n",
    "        \n",
    "        # Check we still have cells to read\n",
    "        if c < len(nb.cells):\n",
    "            \n",
    "            # And dump the contents to STDOUT\n",
    "            print(\"====== \" + nb.cells[c]['cell_type'] + \" ======\")\n",
    "            src = nb.cells[c]['source'].splitlines()\n",
    "            if len(src) > lines:\n",
    "                print('\\n'.join(src[0:lines]))\n",
    "                print(\"...\")\n",
    "            else:\n",
    "                print(nb.cells[c]['source'])\n",
    "\n",
    "def write_metadata(nb, nm, val, namespace=unicode('geopyter')):\n",
    "    \"\"\"\n",
    "    Add or append metadata values to the geopyter parameter.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: nbformat.notebooknode.NotebookNode\n",
    "        A notebook object to which to add Geopyter metadata.\n",
    "    nm: String\n",
    "        The name of the key within the Geopyter dictionary that we want to update.\n",
    "    val: String, List, Dictionary\n",
    "        The value to associate with the key.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for the namespace in the notebook metadata\n",
    "    if not namespace in nb.metadata:\n",
    "        nb.metadata[namespace] = {}\n",
    "    \n",
    "    # And write it\n",
    "    nb.metadata[namespace][nm] = val\n",
    "\n",
    "def get_metadata(nb, nm, namespace=unicode('geopyter')):\n",
    "    \"\"\"\n",
    "    Retrieve metadata values from the geopyter parameter.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: nbformat.notebooknode.NotebookNode\n",
    "        A notebook object to which to add Geopyter metadata.\n",
    "    nm: String\n",
    "        The name of the key within the Geopyter dictionary that we want to retrieve.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for the namespace in the notebook metadata\n",
    "    if not nb.metadata.has_key(namespace):\n",
    "        nb.metadata[namespace] = {}\n",
    "    \n",
    "    # And write it\n",
    "    nb.metadata[namespace][nm] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import importlib\n",
    "def find_libraries(nb):\n",
    "    \"\"\"\n",
    "    Utility function to find libraries imported by notebooks \n",
    "    and assemble them into a group for reporting and testing\n",
    "    purposes.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    nb: nbformat.notebooknode.NotebookNode\n",
    "        A notebook object to search for import statements\n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    libs: Set\n",
    "        A set containing the libraries imported by the notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find and classify the cells by type [code, markdown]\n",
    "    cell_types = get_nb_structure(nb)\n",
    "    \n",
    "    libs  = set()\n",
    "    vlibs = {}\n",
    "    \n",
    "    # Iterate over the code cell-types\n",
    "    for c in cell_types['code']:\n",
    "        try:\n",
    "            #print(\"-\" * 25)\n",
    "            #print(nb.cells[c]['source'])\n",
    "            \n",
    "            # Convert the code into a block of lines\n",
    "            block = nb.cells[c]['source'].splitlines()\n",
    "            # Loop over the lines looking for import-type statements\n",
    "            for l in block: \n",
    "                m = re.match(\"(?:from|import) (\\S+)\", l)\n",
    "                if m:\n",
    "                    libs.add(m.group(1))\n",
    "        except IndexError: #Catch index error (not sure where this comes from)\n",
    "            pass\n",
    "    \n",
    "    # Try to get the versions in use on the machine\n",
    "    for l in libs: \n",
    "        l = l.split('.')[0]\n",
    "        #print(\"Checking version of \" + l)\n",
    "        mod = importlib.import_module(l)\n",
    "        ver = None\n",
    "        try:\n",
    "            ver = mod.__version__\n",
    "        except AttributeError:\n",
    "            try: \n",
    "                ver = mod.version\n",
    "            except AttributeError:\n",
    "                print(\"Unable to determine version for: \" + l)\n",
    "                print(\"Currently we check <module>.__version__ and <moduled>.version\")\n",
    "                pass\n",
    "        vlibs[l] = ver\n",
    "    return vlibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#source_nb = 'atoms/foundations/Dictionaries.ipynb'\n",
    "source_nb = 'atoms/visualization/choropleth_classification.ipynb'\n",
    "inb = read_nb(source_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbformat.notebooknode.NotebookNode"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'nbformat_minor', u'cells', u'nbformat', u'metadata']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author.name': u'Jon Reades', 'committer.name': u'Jon Reades', 'sha': u'92489294558bb26a6b4571b66bf86fda0c4b497b', 'committed_date': 1487680868, 'active_branch': 'master', 'authored_date': datetime.datetime(2017, 2, 21, 12, 41, 8)}\n"
     ]
    }
   ],
   "source": [
    "print(gitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'pysal': '1.13.0', u'scipy': '0.17.1', u'numpy': '1.11.1', u'seaborn': '0.7.1', u'sklearn': '0.17.1'}\n"
     ]
    }
   ],
   "source": [
    "libs = find_libraries(inb)\n",
    "print(libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_metadata(inb, unicode('author'), ['J. Reades', 'S. Rey'])\n",
    "write_metadata(inb, unicode('libraries'), find_libraries(inb))\n",
    "write_metadata(inb, unicode('git'), gitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'anaconda-cloud': {},\n",
       " u'geopyter': {u'author': ['J. Reades', 'S. Rey'],\n",
       "  u'git': {'active_branch': 'master',\n",
       "   'author.name': u'jreades',\n",
       "   'authored_date': datetime.datetime(2017, 2, 22, 11, 3, 1),\n",
       "   'committed_date': 1487761381,\n",
       "   'committer.name': u'jreades',\n",
       "   'sha': u'e3386a990462c6c79c81f6ae108824e0770b7e17'},\n",
       "  u'libraries': {u'numpy': '1.11.1',\n",
       "   u'pysal': '1.13.0',\n",
       "   u'scipy': '0.17.1',\n",
       "   u'seaborn': '0.7.1',\n",
       "   u'sklearn': '0.17.1'}},\n",
       " u'kernelspec': {u'display_name': u'Python [Root]',\n",
       "  u'language': u'python',\n",
       "  u'name': u'Python [Root]'},\n",
       " u'language_info': {u'codemirror_mode': {u'name': u'ipython', u'version': 3},\n",
       "  u'file_extension': u'.py',\n",
       "  u'mimetype': u'text/x-python',\n",
       "  u'name': u'python',\n",
       "  u'nbconvert_exporter': u'python',\n",
       "  u'pygments_lexer': u'ipython3',\n",
       "  u'version': u'3.5.2'}}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inb.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_nb(inb, 'test-metadata.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== markdown ======\n",
      "# Notebook-6: Dictionaries\n",
      "====== markdown ======\n",
      "### Lesson Content \n",
      "\n",
      "Welcome back to the fifth Code Camp notebook! In this lesson we'll contiune our exploration of more advanced data structures. Last time we took a peek at a way to represent ordered collections of items via **lists**.\n",
      "\n",
      "This time we'll use **dictionaries** to create collections of unordered items (this is just an easy distinction - there's much more to it - but it's a good way to start wrapping your head around the subject).\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "dump_nb(inb, cells=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c0 = snb.cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbformat.notebooknode.NotebookNode"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'source', u'cell_type', u'metadata']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'markdown'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0['cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'## Introduction\\n\\n* what is classification\\n* role in choropleth mapping\\n* explore classification using PySAL'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'collapsed': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of cells in  this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_structure(cells):\n",
    "    cell_types = defaultdict(list)\n",
    "    for i, cell in enumerate(cells):\n",
    "        cell_types[cell.cell_type].append(i)\n",
    "    return cell_types\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_types = get_structure(snb.cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'code', u'markdown']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Type: code\t 38 cells\n",
      "Cell Type: markdown\t 11 cells\n"
     ]
    }
   ],
   "source": [
    "for ct, cells in cell_types.items():\n",
    "    print('Cell Type: %s\\t %d cells'% (ct, len(cells)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_cell_idx = cell_types['code'][0]\n",
    "code_cell_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'cell_type': u'code',\n",
       " u'execution_count': 3,\n",
       " u'metadata': {u'collapsed': False},\n",
       " u'outputs': [{u'data': {u'text/plain': u'{\\'description\\': \\'Mexican states regional income 1940-2000\\',\\n \\'explanation\\': [\\'Data used in   Rey, S.J. and M.L.  Sastre Gutierrez. (2010) \"Interregional inequality\\',\\n  \\'dynamics in Mexico.\" Spatial Economic Analysis, 5: 277-298\\',\\n  \\'* mexico.csv: attribute data\\',\\n  \\'* mexico.gal: spatial weights in GAL format\\',\\n  \\'Polygon data, n=32, k=13\\'],\\n \\'name\\': \\'mexico\\'}'},\n",
       "   u'execution_count': 3,\n",
       "   u'metadata': {},\n",
       "   u'output_type': u'execute_result'}],\n",
       " u'source': u\"ps.examples.explain('mexico')\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snb.cells[code_cell_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkd_cell_idx = cell_types['markdown'][0]\n",
    "mkd_cell_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'cell_type': u'markdown',\n",
       " u'metadata': {u'collapsed': True},\n",
       " u'source': u'## Introduction\\n\\n* what is classification\\n* role in choropleth mapping\\n* explore classification using PySAL'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snb.cells[mkd_cell_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Output Cells OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outputs(nb):\n",
    "    \"\"\"Set output attribute of all code cells to be empty\"\"\"\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code':\n",
    "            cell.outputs = []\n",
    "\n",
    "def clear_notebook(old_ipynb, new_ipynb):\n",
    "    with io.open(old_ipynb, 'r') as f:\n",
    "        nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "\n",
    "    remove_outputs(nb)\n",
    "    \n",
    "    with io.open(new_ipynb, 'w', encoding='utf8') as f:\n",
    "        nbformat.write(nb, f, nbformat.NO_CONVERT)\n",
    "\n",
    "source_nb = 'atoms/visualization/choropleth_classification.ipynb'\n",
    "\n",
    "new_nb = 'nout.ipynb'\n",
    "clear_notebook(source_nb, new_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notebook Class for Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_nb = 'atoms/foundations/Dictionaries-Test.ipynb'\n",
    "nb = read_nb(source_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------New Cell--------------------\n",
      "Notebook-6: Dictionaries\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "Lesson Content, In this Notebook\n",
      "--------------------New Cell--------------------\n",
      "Dictionaries\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "Accessing Dictionaries\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "Creating a Simple Phone Book\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "Useful Dictionary Methods\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "Are You On the List? (Part 2)\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "What Do You Do if You're Not On the List?\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "Lists of Lists, Dictionaries of Lists, Dictionaries of Dictionaries... Oh my!\n",
      "A Data Set of City Attributes\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "A Phonebook+\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "Dictionary-of-Dictionaries\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "Code (Applied Geo-example)\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "\n",
      "--------------------New Cell--------------------\n",
      "\n",
      "\n",
      "Further references:\n"
     ]
    }
   ],
   "source": [
    "source_nb = 'atoms/foundations/Dictionaries-Test.ipynb'\n",
    "nb = read_nb(source_nb)\n",
    "\n",
    "import re\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "md = markdown.Markdown()\n",
    "\n",
    "cell_types = get_nb_structure(nb)    \n",
    "\n",
    "# Iterate over the code cell-types\n",
    "for c in cell_types['markdown']:\n",
    "    \n",
    "    # Delete code blocks -- this is a bit brutal \n",
    "    # and it might be better to escape them in some\n",
    "    # way... but this at least works well enough\n",
    "    src = re.sub(r'```.+?```', '', nb.cells[c]['source'], flags=re.S)\n",
    "    \n",
    "    print(\"-\"*20 + \"New Cell\" + \"-\"*20)\n",
    "    soup = BeautifulSoup(md.convert(src), 'html.parser')\n",
    "    \n",
    "    h1 = soup.findAll('h1')\n",
    "    print( \", \".join([x.contents[0] for x in h1]))\n",
    "    \n",
    "    h2 = soup.findAll('h2')\n",
    "    print( \", \".join([x.contents[0] for x in h2]))\n",
    "    \n",
    "    h3 = soup.findAll('h3')\n",
    "    print( \", \".join([x.contents[0] for x in h3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rh1 = re.compile('^# ')\n",
    "rh2 = re.compile('^## ')\n",
    "rh3 = re.compile('^### ')\n",
    "rh4 = re.compile('^#### ')\n",
    "rh = re.compile('^#+')\n",
    "\n",
    "class NoteBook(object):\n",
    "    def __init__(self, ipynb):\n",
    "        self.nb = read_nb(ipynb)\n",
    "        self.structure = get_structure(self.nb.cells)\n",
    "        \n",
    "    def get_cells_by_type(self, cell_type=None):\n",
    "        if cell_type:\n",
    "            cell_type = cell_type.lower()\n",
    "            return [self.nb.cells[i] for i in self.structure[cell_type]]\n",
    "        else:\n",
    "            return self.nb.cells\n",
    "    \n",
    "    def get_cells_by_id(self, ids=[]):\n",
    "        return [self.nb.cells[i] for i in ids]\n",
    "    \n",
    "    def get_header_cells(self):\n",
    "        hs = []\n",
    "        if 'markdown' in self.structure:\n",
    "            idxs = self.structure['markdown']\n",
    "            pairs = zip(idxs, self.get_cells_by_type('markdown'))\n",
    "            hs = [(idx, cell) for idx, cell in pairs if rh.match(cell['source'])]\n",
    "        return hs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NoteBook(source_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cid = nb.get_cells_by_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cid = nb.get_cells_by_id([7, 10, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'cell_type': u'code',\n",
       "  u'execution_count': 5,\n",
       "  u'metadata': {u'collapsed': True},\n",
       "  u'outputs': [],\n",
       "  u'source': u\"y = f.by_col_array('pcgdp2000')\"},\n",
       " {u'cell_type': u'markdown',\n",
       "  u'metadata': {},\n",
       "  u'source': u'#### Sample Mean\\n\\n$\\\\bar{y} = \\\\sum_{i=1}^n y_i$'},\n",
       " {u'cell_type': u'code',\n",
       "  u'execution_count': 1,\n",
       "  u'metadata': {u'collapsed': True},\n",
       "  u'outputs': [],\n",
       "  u'source': u'import pysal as ps'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'# Classification for Choropleth Mapping\\n'}),\n",
       " (1,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {u'collapsed': True},\n",
       "   u'source': u'## Introduction\\n\\n* what is classification\\n* role in choropleth mapping\\n* explore classification using PySAL'}),\n",
       " (3,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'## Data Set: Mexico State Gross Domestic Product'}),\n",
       " (9,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Numerical summaries'}),\n",
       " (10,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'#### Sample Mean\\n\\n$\\\\bar{y} = \\\\sum_{i=1}^n y_i$'}),\n",
       " (12,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'#### Sample Standard Deviation\\n\\n$\\\\hat{\\\\sigma} = \\\\sqrt{\\\\frac{\\\\sum_{i=1}^n (y_i-\\\\bar{y})^2}{n-1}}$'}),\n",
       " (14, {u'cell_type': u'markdown', u'metadata': {}, u'source': u'#### Median'}),\n",
       " (22,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Univariate Distribution Visualization'}),\n",
       " (27,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'## PySAL Classifiers'}),\n",
       " (28,\n",
       "  {u'cell_type': u'markdown', u'metadata': {}, u'source': u'### Quantiles'}),\n",
       " (35,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Equal Interval'}),\n",
       " (37,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Maximum Breaks'}),\n",
       " (39,\n",
       "  {u'cell_type': u'markdown', u'metadata': {}, u'source': u'### Box Plot'}),\n",
       " (41,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Standard Deviation'}),\n",
       " (43,\n",
       "  {u'cell_type': u'markdown', u'metadata': {}, u'source': u'### Head Tail'}),\n",
       " (45,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Jenks Caspall'}),\n",
       " (48,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'### Fisher Jenks'}),\n",
       " (50, {u'cell_type': u'markdown', u'metadata': {}, u'source': u'### max-p'}),\n",
       " (52, {u'cell_type': u'markdown', u'metadata': {}, u'source': u'### Fit'}),\n",
       " (64,\n",
       "  {u'cell_type': u'markdown',\n",
       "   u'metadata': {},\n",
       "   u'source': u'## Consensus classification'})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.get_header_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdict = defaultdict(list)\n",
    "for idx, cell in nb.get_header_cells():\n",
    "    level = cell['source'].count(\"#\")\n",
    "    hdict[level].append(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: [0],\n",
       "             2: [1, 3, 27, 64],\n",
       "             3: [9, 22, 28, 35, 37, 39, 41, 43, 45, 48, 50, 52],\n",
       "             4: [10, 12, 14]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-af303cfc889b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstart_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlast_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# find the start and end cells for each H? block\n",
    "keys = list(hdict.keys())\n",
    "keys.sort(reverse=True)\n",
    "all_keys = keys.copy()\n",
    "start_end = []\n",
    "last_stop = len(nb.nb.cells)\n",
    "while keys:\n",
    "    current = keys.pop(0)\n",
    "    for element in hdict[current]:\n",
    "        above = [k for k in all_keys.copy() if k <= current]\n",
    "        stop = last_stop\n",
    "        while above:\n",
    "            key_above = above.pop()\n",
    "            larger = [v for v in hdict[key_above] if v > element]\n",
    "            if larger:\n",
    "                if larger[0] < stop:\n",
    "                    stop = larger[0]\n",
    "        start_end.append([element, stop])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 12],\n",
       " [12, 14],\n",
       " [14, 22],\n",
       " [9, 22],\n",
       " [22, 27],\n",
       " [28, 35],\n",
       " [35, 37],\n",
       " [37, 39],\n",
       " [39, 41],\n",
       " [41, 43],\n",
       " [43, 45],\n",
       " [45, 48],\n",
       " [48, 50],\n",
       " [50, 52],\n",
       " [52, 64],\n",
       " [1, 3],\n",
       " [3, 27],\n",
       " [27, 64],\n",
       " [64, 99],\n",
       " [0, 99]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end # for each H? cell report the start and end cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: [0],\n",
       "             2: [1, 3, 27, 64],\n",
       "             3: [9, 22, 28, 35, 37, 39, 41, 43, 45, 48, 50, 52],\n",
       "             4: [10, 12, 14]})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nb.get_header_cells())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Data Set: Mexico State Gross Domestic Product\n",
      "ps.examples.available()\n",
      "ps.examples.explain('mexico')\n",
      "f = ps.open(ps.examples.get_path('mexico.csv'))\n",
      "f.header\n",
      "y = f.by_col_array('pcgdp2000')\n",
      "y\n",
      "### Numerical summaries\n",
      "#### Sample Mean\n",
      "\n",
      "$\\bar{y} = \\sum_{i=1}^n y_i$\n",
      "y_mean = y.mean()\n",
      "y_mean\n",
      "#### Sample Standard Deviation\n",
      "\n",
      "$\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n (y_i-\\bar{y})^2}{n-1}}$\n",
      "y_std = y.std()\n",
      "y_std\n",
      "#### Median\n",
      "import numpy as np\n",
      "y_median = np.median(y)\n",
      "y_median\n",
      "(y < y_mean).sum()\n",
      "(y > y_mean).sum()\n",
      "y_sorted = np.sort(y, axis=0)\n",
      "y_sorted\n",
      "y_sorted[15]\n",
      "y_sorted[16]\n",
      "(y_sorted[15]+y_sorted[16])/2.\n",
      "### Univariate Distribution Visualization\n",
      "%pylab inline\n",
      "import seaborn as sns\n",
      "sns.distplot(y)\n",
      "sns.distplot(y, kde=False, rug=True)\n",
      "sns.distplot(y, bins=5, kde=False, rug=True)\n",
      "sns.distplot(y, hist=False,  rug=True)\n"
     ]
    }
   ],
   "source": [
    "# second h2 section with all children\n",
    "se2 = [ v for v in start_end if v[0]==3][0]\n",
    "block = nb.get_cells_by_id(range(*se2))\n",
    "for cell in block:\n",
    "    print(cell['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Numerical summaries\n",
      "#### Sample Mean\n",
      "\n",
      "$\\bar{y} = \\sum_{i=1}^n y_i$\n",
      "y_mean = y.mean()\n",
      "y_mean\n",
      "#### Sample Standard Deviation\n",
      "\n",
      "$\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n (y_i-\\bar{y})^2}{n-1}}$\n",
      "y_std = y.std()\n",
      "y_std\n",
      "#### Median\n",
      "import numpy as np\n",
      "y_median = np.median(y)\n",
      "y_median\n",
      "(y < y_mean).sum()\n",
      "(y > y_mean).sum()\n",
      "y_sorted = np.sort(y, axis=0)\n",
      "y_sorted\n",
      "y_sorted[15]\n",
      "y_sorted[16]\n",
      "(y_sorted[15]+y_sorted[16])/2.\n"
     ]
    }
   ],
   "source": [
    "# first h3 section in second h2 section with all children\n",
    "se3 = [ v for v in start_end if v[0]==9][0]\n",
    "block = nb.get_cells_by_id(range(*se3))\n",
    "for cell in block:\n",
    "    print(cell['source'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
